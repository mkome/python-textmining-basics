{
 "cells": [
  {
   "source": [
    "## Data and Text mining\n",
    "\n",
    "Data mining and Text mining are an essential step in data science, but they are different. Since they have many terminologies overlap each other, they tend to get quite confusing, especially for those trying to find their way around the realm of data science.\n",
    "The purpose of the data science fields is to get insight from the data. To get the actual insight, the data needs to be clean and useful. Data mining is a process used to find and extract patterns within a large set of data. At its core, statistical methodologies is used to describe the relations in the data.\n",
    "\n",
    "In this notebook, I would like to demonstrate basic Data mining techniques related to Text mining by using real data.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## About the data set\n",
    "We use the data set contains all vehicle safety-related defect complaints received by NHTSA since January 1, 1995.\n",
    "\n",
    "The United States Department of Transportation established the Natinal Highway Traffic Safety Administration (NHTSA), so that information on all vehicle safety-related issues is available to sonsumers. NHTSA accepts complaints on auto safety issues, through their website or other channels such as email or phone. Users can enter information about the vehicle (Make - Model - Year) and the incident that contains both constrained choice fields and free text input. As a result, the data available for an incident contains the mixture of structured and unstructured data.\n",
    "\n",
    "The resulting data by the Office of Defects Investigation (ODI) of NHTSA is made publicly available on [NHTSA/ODI Databases](https://www-odi.nhtsa.dot.gov/downloads/). These contents are anonymous in that they do not contain personal identities or license plates. On the complaints data, the field for `COMPDESC` is filled to describe the affected parts.\n",
    "\n",
    "The latest data set is downloaded locally by executing the following code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "nhtsa_dir = 'nhtsa'\n",
    "nhtsa_complaints = os.path.join(nhtsa_dir, 'FLAT_CMPL.txt')\n",
    "\n",
    "if os.path.exists(nhtsa_complaints):\n",
    "    print(\"All complaints file already exists.\")\n",
    "else:\n",
    "    print(\"Downloading all complaints.\")\n",
    "    http = urllib3.PoolManager()\n",
    "    url = 'https://www-odi.nhtsa.dot.gov/downloads/folders/Complaints/FLAT_CMPL.zip'\n",
    "    path = 'FLAT_CMPL.zip'\n",
    "    \n",
    "    with http.request('GET', url, preload_content=False) as r, open(path, 'wb') as out_file:       \n",
    "        shutil.copyfileobj(r, out_file)\n",
    "    \n",
    "    print(\"Unzipping \" + path)\n",
    "    with zipfile.ZipFile(path, 'r') as zf:\n",
    "        zf.extractall(nhtsa_dir)\n",
    "    \n",
    "    print(\"Removing \" + path)\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded complaints are TAB delimited with no headers and 49 fields (see: [CMPL.txt](https://www-odi.nhtsa.dot.gov/downloads/folders/Complaints/CMPL.txt) for data schema). This data set is loaded into a pandas's DataFrame for further analysis. corrupted records to load the all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    nhtsa_complaints, \n",
    "    header=None, \n",
    "    encoding='latin1', \n",
    "    delimiter='\\t', \n",
    "    quoting=csv.QUOTE_NONE, \n",
    "    error_bad_lines=False, \n",
    "    warn_bad_lines=True,\n",
    "    index_col=False,\n",
    "    dtype=str,\n",
    "#    nrows=200000,\n",
    ")\n",
    "\n",
    "df.columns = [\n",
    "    'CMPLID','ODINO','MFR_NAME','MAKETXT','MODELTXT','YEARTXT','CRASH','FAILDATE','FIRE','INJURED','DEATHS','COMPDESC','CITY',\n",
    "    'STATE','VIN','DATEA','LDATE','MILES','OCCURENCES','CDESCR','CMPL_TYPE','POLICE_RPT_YN','PURCH_DT','ORIG_OWNER_YN',\n",
    "    'ANTI_BRAKES_YN','CRUISE_CONT_YN','NUM_CYLS','DRIVE_TRAIN','FUEL_SYS','FUEL_TYPE','TRANS_TYPE','VEH_SPEED','DOT',\n",
    "    'TIRE_SIZE','LOC_OF_TIRE','TIRE_FAIL_TYPE','ORIG_EQUIP_YN','MANUF_DT','SEAT_TYPE','RESTRAINT_TYPE','DEALER_NAME',\n",
    "    'DEALER_TEL','DEALER_CITY','DEALER_STATE','DEALER_ZIP','PROD_TYPE','REPAIRED_YN','MEDICAL_ATTN','VEHICLES_TOWED_YN']"
   ]
  },
  {
   "source": [
    "This data set has 3 date type fields, however some of the fields have corrupted values. We need to drop the records with invalid or problematic values in date type format so that these date fields can be converted into date type field in DataFrame. \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_fields = ['FAILDATE', 'DATEA', 'LDATE', 'PURCH_DT', 'MANUF_DT']\n",
    "\n",
    "# drop rows with invalid values in datetime fields like '0YYYYMDD'\n",
    "for date_field in date_fields:\n",
    "    # drop error values in datetime fields like `0YYYYMDD`\n",
    "    df = df[(df[date_field].isna()) | (df[date_field].str.match(r'(?P<year>(19|20)\\d{2})(?P<month>\\d{1})(?P<day>\\d{2})'))]\n",
    "\n",
    "# convert to datetime type\n",
    "for date_field in date_fields:\n",
    "    df[date_field] = pd.to_datetime(df[date_field])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look on the data set\n",
    "This data set has more than 1.7 million records with 49 fields (as of 2021-05-17)."
   ]
  },
  {
   "source": [
    "df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "The following figure shows the number of complaints for each year from 1995 to 2021."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df['DATEA'].value_counts().resample('YS').sum()\n",
    "ax = timeseries.plot(kind='bar')\n",
    "# beware that '_' is important to absorb matplotlib verbose messages\n",
    "_ = ax.set_xticklabels([x.strftime(\"%Y\") for x in timeseries.index])\n"
   ]
  },
  {
   "source": [
    "The following shows the most 30 frequent components in the all complaints data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COMPDESC'].value_counts().head(30).plot(kind='bar')"
   ]
  },
  {
   "source": [
    "## Toyota Tundra Recall for Frame Rust\n",
    "Toyota has recalled some of its Tundra pickups for dangerous frame corrosion. This problem could eventually cause the frame to break apart, potentially causing serious accidents, but in any case making the trucks unusable. The Tundra recall affects the model years 2000-2003, sold in or registered in states where corrosive road salt is an issue.\n",
    "- Recall Subject: REAR CROSS MEMBER ASSEMBLY CORROSION\n",
    "- Report Receipt Date: NOV 18, 2009\n",
    "- NHTSA Campaign Number: 09V444000\n",
    "- Component(s): STRUCTURE\n",
    "\n",
    "The data uncovers this actual recall case. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Which components are highly relevant to \"Toyota Tundra\"\n",
    "The following figure shows the 30 most frequent components to \"Toyota Tundra\". The `STRUCTURE:BODY` component is the most frequent component in the set of complaints to `TUNDRA` model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeltxt = df[df['MODELTXT']=='TUNDRA']\n",
    "compdesc_modeltxt=df_modeltxt['COMPDESC']\n",
    "compdesc_modeltxt.value_counts().head(30).plot(kind='bar')"
   ]
  },
  {
   "source": [
    "The following figure shows the 30 most relevant components to \"Toyota Tundra\". The 30 most frequents components are sorted by PMI (Pointwise Mutual Information) measure. This measure represents how strongly the component is related to the set of complaints to `TUNDRA` model, compared to the other complaints in this data set. Therefore, the `STRUCTURE: FRAME AND MEMBERS:UNDERBODY SHIELDS` components is more specifically related to \"Toyota Tundra\" in this data set.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "corpus_count = len(df)\n",
    "modeltxt_count = len(df_modeltxt)\n",
    "compdesc_modeltxt_counts = compdesc_modeltxt.value_counts().head(30)\n",
    "compdesc_modeltxt_pmi = pd.Series(name='pmi', dtype='float64')\n",
    "for compdesc in compdesc_modeltxt_counts.index:\n",
    "    compdesc_count = (df['COMPDESC']==compdesc).sum()\n",
    "    compdesc_modeltxt_count = compdesc_modeltxt_counts[compdesc]\n",
    "    pmi = math.log( (compdesc_modeltxt_count * corpus_count) / (modeltxt_count * compdesc_count) )\n",
    "    compdesc_modeltxt_pmi[compdesc] = pmi\n",
    "    \n",
    "compdesc_modeltxt_pmi.sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "source": [
    "The following funcation returns the most relevant values in the given contents with in the set of selected documents."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "def get_significant_values(\n",
    "    selected : Series,\n",
    "    contents : Series,\n",
    "    n : int    \n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieve significant values in the contents.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    selected : Series\n",
    "        Series of True or False to represents selections\n",
    "    contents : Series\n",
    "        Data for contents\n",
    "    n : int\n",
    "        Number of significant values to be returned\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Series of significant values in the contents\n",
    "    \n",
    "    \"\"\"\n",
    "    assert len(selected)==len(contents) , 'The length of the series of selections and contents is not equal. '\n",
    "    \n",
    "    total_size = len(selected)\n",
    "    size = selected.sum()\n",
    "    \n",
    "    significant_values = contents[selected].value_counts(sort=True, ascending=False).head(n).astype('float64')\n",
    "    for value, freq in significant_values.items():\n",
    "        total_freq = (contents==value).sum()\n",
    "        significant_values[value] = math.log( (freq * total_size) / (size * total_freq) )\n",
    "    \n",
    "    return significant_values.sort_values(ascending=False)"
   ]
  },
  {
   "source": [
    "Here is the example to retrieve the most `30` relevant values in `COMPDESC` field with the selection `MODELTXT='TUNDRA'`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_values = get_significant_values(\n",
    "    df['MODELTXT']=='TUNDRA',\n",
    "    df['COMPDESC'], \n",
    "    30\n",
    ")\n",
    "significant_values.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are STRUCTURE: FRAME AND MEMBERS:UNDERBODY SHIELDS highly related to \"Toyota Tundra\"?\n",
    "To answer that question, let us look closer at which fields are related to `STRUCTURE: FRAME AND MEMBERS:UNDERBODY SHIELDS`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_complaints = ((df['MODELTXT'] == 'TUNDRA') & (df['COMPDESC'] == significant_values.index[0]))"
   ]
  },
  {
   "source": [
    "### Treands related to Model Year and Mileage\n",
    "\n",
    "The following code displays the relevancy of complaints for each model year from 2000 to 2020, and separately a bar graph of the relevancy to the car's mileage. By far, the most related model year is 2000. And in this case, the more mileage a car has the more related it is."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_significant_values(selected_complaints, df['YEARTXT'], 30).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_significant_values(selected_complaints, pd.to_numeric(df['MILES']).round(-4), 10).plot(kind='bar')"
   ]
  },
  {
   "source": [
    "### View data in a heatmap\n",
    "The code below displays a heat map of relevant data in the United States.\n",
    "Many of the relevant complaints are related to the New England area."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data\"\n",
    ")\n",
    "state_geo = f\"{url}/us-states.json\"\n",
    "\n",
    "m = folium.Map(location=[48, -102], zoom_start=3)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=state_geo,\n",
    "    name=\"choropleth\",\n",
    "    data=get_significant_values(\n",
    "        selected_complaints,\n",
    "        df['STATE'],\n",
    "        30\n",
    "    ).rename_axis('State').reset_index(name='Relevancy'),\n",
    "    columns=[\"State\", \"Relevancy\"],\n",
    "    key_on=\"feature.id\",\n",
    "    fill_color=\"YlGn\",\n",
    "    nan_fill_color=\"white\",\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name=\"Relevancy\",\n",
    ").add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.9.2 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}